{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.4"
    },
    "colab": {
      "name": "Ngrams.ipynb",
      "provenance": []
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "ytSxnOwB1yaE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# ngrams for Cyberthon 2020 - 90.53% Accuracy\n",
        "# By richdom2185\n",
        "\n",
        "import nltk\n",
        "import random\n",
        "import re\n",
        "\n",
        "# Open and read the file\n",
        "text = open('PriceAndPrejudice.txt', encoding='utf-8').read()\n",
        "print(text[:300])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mnunm8_awGtl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Convert all to lowercase and drop non-essential characters\n",
        "text = re.sub('[^a-zA-z0-9_.“”,\\s]', '', text.lower())\n",
        "text = re.sub('[\\n]+', ' ', text)\n",
        "print(text[:300])\n",
        "\n",
        "# Run this for troubleshooting -- saves the file so you can view using text editor\n",
        "#f = open(\"text.txt\", \"w\")\n",
        "#f.write(text)\n",
        "#f.close()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FVqzL0xH1yaM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Split the texts into tokens\n",
        "nltk.download('punkt')\n",
        "tokens = nltk.word_tokenize(text)\n",
        "print(tokens[:50])\n",
        "\n",
        "# Run this for troubleshooting -- saves the file so you can view using text editor\n",
        "#f = open(\"tokens.txt\", \"w\")\n",
        "#for line in (token + '\\n' for token in tokens):\n",
        "#  f.write(line)\n",
        "#f.close()\n",
        "\n",
        "# Create bi, tri, ..., n-grams\n",
        "from nltk.util import ngrams\n",
        "grams_2 = list(ngrams(tokens, 2))\n",
        "grams_3 = list(ngrams(tokens, 3))\n",
        "grams_4 = list(ngrams(tokens, 4))\n",
        "grams_5 = list(ngrams(tokens, 5))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gmSetJruzjs1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Load queries and format them correctly\n",
        "queries = [tuple(line[1:-2].replace(\"'\", '').split(', ')) for line in open('query.txt', encoding='utf-8').readlines()]\n",
        "print(queries)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MXFg85H-LMWi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Convert queries to all lowercase\n",
        "edited_queries = []\n",
        "for query in queries:\n",
        "  query = tuple([element.lower() for element in query])\n",
        "  edited_queries.append(query)\n",
        "queries = edited_queries.copy()\n",
        "print(queries)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UqDHG7xHGn-9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Count the number of occurences of each query in the text\n",
        "counts = []\n",
        "for query in queries:\n",
        "  count = 0\n",
        "  if len(query) == 2:\n",
        "    for gram in grams_2:\n",
        "      if gram == query: count += 1\n",
        "    counts.append(count)\n",
        "  elif len(query) == 3:\n",
        "    for gram in grams_3:\n",
        "      if gram == query: count += 1\n",
        "    counts.append(count)\n",
        "  elif len(query) == 4:\n",
        "    for gram in grams_4:\n",
        "      if gram == query: count += 1\n",
        "    counts.append(count)\n",
        "  elif len(query) == 5:\n",
        "    for gram in grams_5:\n",
        "      if gram == query: count += 1\n",
        "    counts.append(count)\n",
        "  #print(query, count)\n",
        "print(counts)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OGDG-pPqH6SX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Convert to CSV\n",
        "import pandas as pd\n",
        "output = pd.DataFrame({'id': [i for i in range(len(counts))], 'count': counts})\n",
        "output.to_csv('ngrams-submission.csv', index=False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bopJrDnIuin-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Submit to CTFSG Grader\n",
        "import urllib.request, os\n",
        "urllib.request.urlretrieve('https://raw.githubusercontent.com/alttablabs/ctfsg-utils/master/pyctfsglib.py', './pyctfsglib.py')\n",
        "print('Downloaded pyctfsglib.py:', 'pyctfsglib.py' in os.listdir())\n",
        "\n",
        "import pyctfsglib as ctfsg\n",
        "import random\n",
        "\n",
        "USER_TOKEN = \"REDACTED\" # You need to fill this up\n",
        "GRADER_URL = random.choice([\n",
        "\"http://challenges.csdc20t.ctf.sg:30021/\",\n",
        "\"http://challenges.csdc20t.ctf.sg:30022/\"\n",
        "])\n",
        "\n",
        "grader = ctfsg.DSGraderClient(GRADER_URL, USER_TOKEN)\n",
        "\n",
        "# Submitting a file\n",
        "grader.submitFile('./ngrams-submission.csv')"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}